{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# Requirements and Dependencies"
      ],
      "metadata": {
        "id": "Ua0_AbO8JsB3"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install --quiet torch torchvision torchaudio==2.3.0 scikit-learn tqdm"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "70FkpzNpJSiG",
        "outputId": "99949912-e1f3-4b2a-8d17-6ece458fbd79"
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m3.4/3.4 MB\u001b[0m \u001b[31m25.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m779.2/779.2 MB\u001b[0m \u001b[31m1.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m410.6/410.6 MB\u001b[0m \u001b[31m3.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m14.1/14.1 MB\u001b[0m \u001b[31m95.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m23.7/23.7 MB\u001b[0m \u001b[31m63.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m823.6/823.6 kB\u001b[0m \u001b[31m52.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m731.7/731.7 MB\u001b[0m \u001b[31m1.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m121.6/121.6 MB\u001b[0m \u001b[31m7.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m56.5/56.5 MB\u001b[0m \u001b[31m13.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m124.2/124.2 MB\u001b[0m \u001b[31m7.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m196.0/196.0 MB\u001b[0m \u001b[31m5.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m176.2/176.2 MB\u001b[0m \u001b[31m7.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m99.1/99.1 kB\u001b[0m \u001b[31m9.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m168.1/168.1 MB\u001b[0m \u001b[31m7.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m7.0/7.0 MB\u001b[0m \u001b[31m116.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install -U openai-whisper"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "rnyus7XX9U4l",
        "outputId": "d0ccb381-91a4-4ae0-aefc-4926b16d9242"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting openai-whisper\n",
            "  Downloading openai-whisper-20240930.tar.gz (800 kB)\n",
            "\u001b[?25l     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m0.0/800.5 kB\u001b[0m \u001b[31m?\u001b[0m eta \u001b[36m-:--:--\u001b[0m\r\u001b[2K     \u001b[91m━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[91m╸\u001b[0m\u001b[90m━━━━━━━━━━\u001b[0m \u001b[32m583.7/800.5 kB\u001b[0m \u001b[31m17.1 MB/s\u001b[0m eta \u001b[36m0:00:01\u001b[0m\r\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m800.5/800.5 kB\u001b[0m \u001b[31m14.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Installing build dependencies ... \u001b[?25l\u001b[?25hdone\n",
            "  Getting requirements to build wheel ... \u001b[?25l\u001b[?25hdone\n",
            "  Preparing metadata (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n",
            "Requirement already satisfied: numba in /usr/local/lib/python3.11/dist-packages (from openai-whisper) (0.60.0)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.11/dist-packages (from openai-whisper) (2.0.2)\n",
            "Requirement already satisfied: torch in /usr/local/lib/python3.11/dist-packages (from openai-whisper) (2.3.0)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.11/dist-packages (from openai-whisper) (4.67.1)\n",
            "Requirement already satisfied: more-itertools in /usr/local/lib/python3.11/dist-packages (from openai-whisper) (10.7.0)\n",
            "Requirement already satisfied: tiktoken in /usr/local/lib/python3.11/dist-packages (from openai-whisper) (0.9.0)\n",
            "Requirement already satisfied: triton>=2.0.0 in /usr/local/lib/python3.11/dist-packages (from openai-whisper) (2.3.0)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.11/dist-packages (from triton>=2.0.0->openai-whisper) (3.18.0)\n",
            "Requirement already satisfied: llvmlite<0.44,>=0.43.0dev0 in /usr/local/lib/python3.11/dist-packages (from numba->openai-whisper) (0.43.0)\n",
            "Requirement already satisfied: regex>=2022.1.18 in /usr/local/lib/python3.11/dist-packages (from tiktoken->openai-whisper) (2024.11.6)\n",
            "Requirement already satisfied: requests>=2.26.0 in /usr/local/lib/python3.11/dist-packages (from tiktoken->openai-whisper) (2.32.3)\n",
            "Requirement already satisfied: typing-extensions>=4.8.0 in /usr/local/lib/python3.11/dist-packages (from torch->openai-whisper) (4.13.2)\n",
            "Requirement already satisfied: sympy in /usr/local/lib/python3.11/dist-packages (from torch->openai-whisper) (1.13.1)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.11/dist-packages (from torch->openai-whisper) (3.4.2)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.11/dist-packages (from torch->openai-whisper) (3.1.6)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.11/dist-packages (from torch->openai-whisper) (2025.3.2)\n",
            "Requirement already satisfied: nvidia-cuda-nvrtc-cu12==12.1.105 in /usr/local/lib/python3.11/dist-packages (from torch->openai-whisper) (12.1.105)\n",
            "Requirement already satisfied: nvidia-cuda-runtime-cu12==12.1.105 in /usr/local/lib/python3.11/dist-packages (from torch->openai-whisper) (12.1.105)\n",
            "Requirement already satisfied: nvidia-cuda-cupti-cu12==12.1.105 in /usr/local/lib/python3.11/dist-packages (from torch->openai-whisper) (12.1.105)\n",
            "Requirement already satisfied: nvidia-cudnn-cu12==8.9.2.26 in /usr/local/lib/python3.11/dist-packages (from torch->openai-whisper) (8.9.2.26)\n",
            "Requirement already satisfied: nvidia-cublas-cu12==12.1.3.1 in /usr/local/lib/python3.11/dist-packages (from torch->openai-whisper) (12.1.3.1)\n",
            "Requirement already satisfied: nvidia-cufft-cu12==11.0.2.54 in /usr/local/lib/python3.11/dist-packages (from torch->openai-whisper) (11.0.2.54)\n",
            "Requirement already satisfied: nvidia-curand-cu12==10.3.2.106 in /usr/local/lib/python3.11/dist-packages (from torch->openai-whisper) (10.3.2.106)\n",
            "Requirement already satisfied: nvidia-cusolver-cu12==11.4.5.107 in /usr/local/lib/python3.11/dist-packages (from torch->openai-whisper) (11.4.5.107)\n",
            "Requirement already satisfied: nvidia-cusparse-cu12==12.1.0.106 in /usr/local/lib/python3.11/dist-packages (from torch->openai-whisper) (12.1.0.106)\n",
            "Requirement already satisfied: nvidia-nccl-cu12==2.20.5 in /usr/local/lib/python3.11/dist-packages (from torch->openai-whisper) (2.20.5)\n",
            "Requirement already satisfied: nvidia-nvtx-cu12==12.1.105 in /usr/local/lib/python3.11/dist-packages (from torch->openai-whisper) (12.1.105)\n",
            "Requirement already satisfied: nvidia-nvjitlink-cu12 in /usr/local/lib/python3.11/dist-packages (from nvidia-cusolver-cu12==11.4.5.107->torch->openai-whisper) (12.5.82)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests>=2.26.0->tiktoken->openai-whisper) (3.4.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.11/dist-packages (from requests>=2.26.0->tiktoken->openai-whisper) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests>=2.26.0->tiktoken->openai-whisper) (2.4.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.11/dist-packages (from requests>=2.26.0->tiktoken->openai-whisper) (2025.4.26)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.11/dist-packages (from jinja2->torch->openai-whisper) (3.0.2)\n",
            "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.11/dist-packages (from sympy->torch->openai-whisper) (1.3.0)\n",
            "Building wheels for collected packages: openai-whisper\n",
            "  Building wheel for openai-whisper (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for openai-whisper: filename=openai_whisper-20240930-py3-none-any.whl size=803406 sha256=a489c44b9ce326be2353d395f8a35552ef22c3737451e272abf4915a4f7c0130\n",
            "  Stored in directory: /root/.cache/pip/wheels/2f/f2/ce/6eb23db4091d026238ce76703bd66da60b969d70bcc81d5d3a\n",
            "Successfully built openai-whisper\n",
            "Installing collected packages: openai-whisper\n",
            "Successfully installed openai-whisper-20240930\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import gdown\n",
        "import math\n",
        "import random\n",
        "import copy\n",
        "import numpy as np\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "from torch.utils.data import TensorDataset, DataLoader, WeightedRandomSampler\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.preprocessing import StandardScaler, LabelEncoder\n",
        "from sklearn.metrics import accuracy_score\n",
        "from tqdm.auto import tqdm\n",
        "import torch.optim as optim\n",
        "import torchaudio\n",
        "from torchaudio.transforms import MFCC, MelSpectrogram, Spectrogram\n",
        "import torchaudio.functional as F_audio\n",
        "import whisper\n",
        "from google.colab import files"
      ],
      "metadata": {
        "id": "NVb0bdqZFT27"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Importing Dataset"
      ],
      "metadata": {
        "id": "mtyNyDOiJxgo"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Download files using gdown\n",
        "gdown.download(\"https://drive.google.com/uc?id=18bOzeo7zRwBI6P-TNW8TLYWNwEyfm4Fi\", output=\"genderpred.csv\", quiet=False)\n",
        "gdown.download(\"https://drive.google.com/uc?id=13hGUN5ACAn8mu-3LVqbhYKpOVJrc4Zif\", output=\"accentpred.csv\", quiet=False)\n",
        "gdown.download(\"https://drive.google.com/uc?id=1IrvjA06lDy2D7WOkYv_dIJJwF-sLbU8s\", output=\"agepred.csv\", quiet=False)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 291
        },
        "id": "DKabJPVBFyJ2",
        "outputId": "1bd1a455-b5f8-4c82-8378-7837bb6d36f6"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Downloading...\n",
            "From (original): https://drive.google.com/uc?id=18bOzeo7zRwBI6P-TNW8TLYWNwEyfm4Fi\n",
            "From (redirected): https://drive.google.com/uc?id=18bOzeo7zRwBI6P-TNW8TLYWNwEyfm4Fi&confirm=t&uuid=175f5b75-5a34-436e-8ba7-3ad2fd9f850c\n",
            "To: /content/genderpred.csv\n",
            "100%|██████████| 126M/126M [00:01<00:00, 83.3MB/s]\n",
            "Downloading...\n",
            "From: https://drive.google.com/uc?id=13hGUN5ACAn8mu-3LVqbhYKpOVJrc4Zif\n",
            "To: /content/accentpred.csv\n",
            "100%|██████████| 70.0M/70.0M [00:01<00:00, 67.5MB/s]\n",
            "Downloading...\n",
            "From: https://drive.google.com/uc?id=1IrvjA06lDy2D7WOkYv_dIJJwF-sLbU8s\n",
            "To: /content/agepred.csv\n",
            "100%|██████████| 76.8M/76.8M [00:00<00:00, 130MB/s]\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'agepred.csv'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 4
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "accent_df=pd.read_csv(\"/content/accentpred.csv\")\n",
        "age_df=pd.read_csv(\"/content/agepred.csv\")\n",
        "gender_df=pd.read_csv(\"/content/genderpred.csv\")"
      ],
      "metadata": {
        "id": "PBvdh-qdFVRU"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "accent_df.columns"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "O1wK5uuG62VE",
        "outputId": "6dcb1bb8-f54b-4ccd-c8b2-e0bffe40c162"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Index(['filename', 'accent', 'mel_energy_mean', 'mel_energy_std',\n",
              "       'spectral_centroid_mean', 'spectral_centroid_std', 'spectral_flux',\n",
              "       'rms_mean', 'rms_std', 'zero_crossing_rate', 'energy_variability',\n",
              "       'pitch_mean', 'pitch_std', 'pitch_range', 'jitter_local',\n",
              "       'voiced_fraction', 'unique_id', 'mfcc1_mean', 'mfcc1_std', 'mfcc2_mean',\n",
              "       'mfcc2_std', 'mfcc3_mean', 'mfcc3_std', 'mfcc4_mean', 'mfcc4_std',\n",
              "       'mfcc5_mean', 'mfcc5_std', 'mfcc6_mean', 'mfcc6_std', 'mfcc7_mean',\n",
              "       'mfcc7_std', 'mfcc8_mean', 'mfcc8_std', 'mfcc9_mean', 'mfcc9_std',\n",
              "       'mfcc10_mean', 'mfcc10_std', 'mfcc11_mean', 'mfcc11_std', 'mfcc12_mean',\n",
              "       'mfcc12_std', 'mfcc13_mean', 'mfcc13_std', 'mfcc14_mean', 'mfcc14_std',\n",
              "       'mfcc15_mean', 'mfcc15_std', 'mfcc16_mean', 'mfcc16_std', 'mfcc17_mean',\n",
              "       'mfcc17_std', 'mfcc18_mean', 'mfcc18_std', 'mfcc19_mean', 'mfcc19_std',\n",
              "       'mfcc20_mean', 'mfcc20_std', 'mfcc21_mean', 'mfcc21_std', 'mfcc22_mean',\n",
              "       'mfcc22_std', 'mfcc23_mean', 'mfcc23_std', 'mfcc24_mean', 'mfcc24_std',\n",
              "       'mfcc25_mean', 'mfcc25_std', 'mfcc26_mean', 'mfcc26_std', 'mfcc27_mean',\n",
              "       'mfcc27_std', 'mfcc28_mean', 'mfcc28_std', 'mfcc29_mean', 'mfcc29_std',\n",
              "       'mfcc30_mean', 'mfcc30_std', 'mfcc31_mean', 'mfcc31_std', 'mfcc32_mean',\n",
              "       'mfcc32_std', 'mfcc33_mean', 'mfcc33_std', 'mfcc34_mean', 'mfcc34_std',\n",
              "       'mfcc35_mean', 'mfcc35_std', 'mfcc36_mean', 'mfcc36_std', 'mfcc37_mean',\n",
              "       'mfcc37_std', 'mfcc38_mean', 'mfcc38_std', 'mfcc39_mean', 'mfcc39_std',\n",
              "       'mfcc40_mean', 'mfcc40_std'],\n",
              "      dtype='object')"
            ]
          },
          "metadata": {},
          "execution_count": 6
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "age_df.columns"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "CdwJrUvQPrfN",
        "outputId": "17a6384f-90dc-4a25-f8d8-f4746a8c5408"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Index(['filename', 'age', 'mel_energy_mean', 'mel_energy_std',\n",
              "       'spectral_centroid_mean', 'spectral_centroid_std', 'spectral_flux',\n",
              "       'rms_mean', 'rms_std', 'zero_crossing_rate', 'energy_variability',\n",
              "       'pitch_mean', 'pitch_std', 'pitch_range', 'jitter_local',\n",
              "       'voiced_fraction', 'unique_id', 'mfcc1_mean', 'mfcc1_std', 'mfcc2_mean',\n",
              "       'mfcc2_std', 'mfcc3_mean', 'mfcc3_std', 'mfcc4_mean', 'mfcc4_std',\n",
              "       'mfcc5_mean', 'mfcc5_std', 'mfcc6_mean', 'mfcc6_std', 'mfcc7_mean',\n",
              "       'mfcc7_std', 'mfcc8_mean', 'mfcc8_std', 'mfcc9_mean', 'mfcc9_std',\n",
              "       'mfcc10_mean', 'mfcc10_std', 'mfcc11_mean', 'mfcc11_std', 'mfcc12_mean',\n",
              "       'mfcc12_std', 'mfcc13_mean', 'mfcc13_std', 'mfcc14_mean', 'mfcc14_std',\n",
              "       'mfcc15_mean', 'mfcc15_std', 'mfcc16_mean', 'mfcc16_std', 'mfcc17_mean',\n",
              "       'mfcc17_std', 'mfcc18_mean', 'mfcc18_std', 'mfcc19_mean', 'mfcc19_std',\n",
              "       'mfcc20_mean', 'mfcc20_std', 'mfcc21_mean', 'mfcc21_std', 'mfcc22_mean',\n",
              "       'mfcc22_std', 'mfcc23_mean', 'mfcc23_std', 'mfcc24_mean', 'mfcc24_std',\n",
              "       'mfcc25_mean', 'mfcc25_std', 'mfcc26_mean', 'mfcc26_std', 'mfcc27_mean',\n",
              "       'mfcc27_std', 'mfcc28_mean', 'mfcc28_std', 'mfcc29_mean', 'mfcc29_std',\n",
              "       'mfcc30_mean', 'mfcc30_std', 'mfcc31_mean', 'mfcc31_std', 'mfcc32_mean',\n",
              "       'mfcc32_std', 'mfcc33_mean', 'mfcc33_std', 'mfcc34_mean', 'mfcc34_std',\n",
              "       'mfcc35_mean', 'mfcc35_std', 'mfcc36_mean', 'mfcc36_std', 'mfcc37_mean',\n",
              "       'mfcc37_std', 'mfcc38_mean', 'mfcc38_std', 'mfcc39_mean', 'mfcc39_std',\n",
              "       'mfcc40_mean', 'mfcc40_std'],\n",
              "      dtype='object')"
            ]
          },
          "metadata": {},
          "execution_count": 7
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "gender_df.columns"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ist2lEIl614e",
        "outputId": "578ffcf1-a3d0-4ad5-b792-d4a80c8aac99"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Index(['filename', 'gender', 'mel_energy_mean', 'mel_energy_std',\n",
              "       'spectral_centroid_mean', 'spectral_centroid_std', 'spectral_flux',\n",
              "       'rms_mean', 'rms_std', 'zero_crossing_rate', 'energy_variability',\n",
              "       'pitch_mean', 'pitch_std', 'pitch_range', 'jitter_local',\n",
              "       'voiced_fraction', 'unique_id', 'mfcc1_mean', 'mfcc1_std', 'mfcc2_mean',\n",
              "       'mfcc2_std', 'mfcc3_mean', 'mfcc3_std', 'mfcc4_mean', 'mfcc4_std',\n",
              "       'mfcc5_mean', 'mfcc5_std', 'mfcc6_mean', 'mfcc6_std', 'mfcc7_mean',\n",
              "       'mfcc7_std', 'mfcc8_mean', 'mfcc8_std', 'mfcc9_mean', 'mfcc9_std',\n",
              "       'mfcc10_mean', 'mfcc10_std', 'mfcc11_mean', 'mfcc11_std', 'mfcc12_mean',\n",
              "       'mfcc12_std', 'mfcc13_mean', 'mfcc13_std', 'mfcc14_mean', 'mfcc14_std',\n",
              "       'mfcc15_mean', 'mfcc15_std', 'mfcc16_mean', 'mfcc16_std', 'mfcc17_mean',\n",
              "       'mfcc17_std', 'mfcc18_mean', 'mfcc18_std', 'mfcc19_mean', 'mfcc19_std',\n",
              "       'mfcc20_mean', 'mfcc20_std', 'mfcc21_mean', 'mfcc21_std', 'mfcc22_mean',\n",
              "       'mfcc22_std', 'mfcc23_mean', 'mfcc23_std', 'mfcc24_mean', 'mfcc24_std',\n",
              "       'mfcc25_mean', 'mfcc25_std', 'mfcc26_mean', 'mfcc26_std', 'mfcc27_mean',\n",
              "       'mfcc27_std', 'mfcc28_mean', 'mfcc28_std', 'mfcc29_mean', 'mfcc29_std',\n",
              "       'mfcc30_mean', 'mfcc30_std', 'mfcc31_mean', 'mfcc31_std', 'mfcc32_mean',\n",
              "       'mfcc32_std', 'mfcc33_mean', 'mfcc33_std', 'mfcc34_mean', 'mfcc34_std',\n",
              "       'mfcc35_mean', 'mfcc35_std', 'mfcc36_mean', 'mfcc36_std', 'mfcc37_mean',\n",
              "       'mfcc37_std', 'mfcc38_mean', 'mfcc38_std', 'mfcc39_mean', 'mfcc39_std',\n",
              "       'mfcc40_mean', 'mfcc40_std'],\n",
              "      dtype='object')"
            ]
          },
          "metadata": {},
          "execution_count": 8
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Feature Selection"
      ],
      "metadata": {
        "id": "inQq_2x2Jiwu"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "id": "RcvYfBFeE38R"
      },
      "outputs": [],
      "source": [
        "balanced_gender_features = ['gender',\n",
        "    # Pitch & voice quality\n",
        "    'pitch_mean', 'pitch_std', 'pitch_range', 'jitter_local', 'voiced_fraction',\n",
        "    # Spectral/energy\n",
        "    'spectral_centroid_mean', 'spectral_centroid_std', 'mel_energy_mean', 'rms_mean', 'zero_crossing_rate',\n",
        "    # MFCC 1-13 (mean + std)\n",
        "    'mfcc1_mean', 'mfcc1_std', 'mfcc2_mean', 'mfcc2_std', 'mfcc3_mean', 'mfcc3_std',\n",
        "    'mfcc4_mean', 'mfcc4_std', 'mfcc5_mean', 'mfcc5_std', 'mfcc6_mean', 'mfcc6_std',\n",
        "    'mfcc7_mean', 'mfcc7_std', 'mfcc8_mean', 'mfcc8_std', 'mfcc9_mean', 'mfcc9_std',\n",
        "    'mfcc10_mean', 'mfcc10_std', 'mfcc11_mean', 'mfcc11_std', 'mfcc12_mean', 'mfcc12_std',\n",
        "    'mfcc13_mean', 'mfcc13_std', 'mfcc14_mean', 'mfcc14_std',\n",
        "    'mfcc15_mean', 'mfcc15_std', 'mfcc16_mean', 'mfcc16_std',\n",
        "    'mfcc17_mean', 'mfcc17_std', 'mfcc18_mean', 'mfcc18_std',\n",
        "    'mfcc19_mean', 'mfcc19_std', 'mfcc20_mean', 'mfcc20_std'\n",
        "]"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "balanced_accent_features = ['accent',\n",
        "    # Prosody/Pitch\n",
        "    'pitch_mean', 'pitch_std', 'pitch_range', 'jitter_local',\n",
        "    # Spectral\n",
        "    'spectral_centroid_mean', 'spectral_centroid_std', 'spectral_flux',\n",
        "    # Energy\n",
        "    'mel_energy_mean', 'rms_mean', 'energy_variability',\n",
        "    # Temporal\n",
        "    'zero_crossing_rate', 'voiced_fraction',\n",
        "    # MFCCs (1-20, mean + std)\n",
        "    'mfcc1_mean', 'mfcc1_std', 'mfcc2_mean', 'mfcc2_std',\n",
        "    'mfcc3_mean', 'mfcc3_std', 'mfcc4_mean', 'mfcc4_std',\n",
        "    'mfcc5_mean', 'mfcc5_std', 'mfcc6_mean', 'mfcc6_std',\n",
        "    'mfcc7_mean', 'mfcc7_std', 'mfcc8_mean', 'mfcc8_std',\n",
        "    'mfcc9_mean', 'mfcc9_std', 'mfcc10_mean', 'mfcc10_std',\n",
        "    'mfcc11_mean', 'mfcc11_std', 'mfcc12_mean', 'mfcc12_std',\n",
        "    'mfcc13_mean', 'mfcc13_std', 'mfcc14_mean', 'mfcc14_std',\n",
        "    'mfcc15_mean', 'mfcc15_std', 'mfcc16_mean', 'mfcc16_std',\n",
        "    'mfcc17_mean', 'mfcc17_std', 'mfcc18_mean', 'mfcc18_std',\n",
        "    'mfcc19_mean', 'mfcc19_std', 'mfcc20_mean', 'mfcc20_std', 'mfcc21_mean', 'mfcc21_std', 'mfcc22_mean',\n",
        "       'mfcc22_std', 'mfcc23_mean', 'mfcc23_std', 'mfcc24_mean', 'mfcc24_std',\n",
        "       'mfcc25_mean', 'mfcc25_std', 'mfcc26_mean', 'mfcc26_std', 'mfcc27_mean',\n",
        "       'mfcc27_std', 'mfcc28_mean', 'mfcc28_std', 'mfcc29_mean', 'mfcc29_std',\n",
        "       'mfcc30_mean', 'mfcc30_std'\n",
        "]"
      ],
      "metadata": {
        "id": "imRT3YFtFJ1r"
      },
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "balanced_age_features = ['age', 'mel_energy_mean', 'mel_energy_std',\n",
        "       'spectral_centroid_mean', 'spectral_centroid_std', 'spectral_flux',\n",
        "       'rms_mean', 'rms_std', 'zero_crossing_rate', 'energy_variability',\n",
        "       'pitch_mean', 'pitch_std', 'pitch_range', 'jitter_local',\n",
        "       'voiced_fraction', 'mfcc1_mean', 'mfcc1_std', 'mfcc2_mean',\n",
        "       'mfcc2_std', 'mfcc3_mean', 'mfcc3_std', 'mfcc4_mean', 'mfcc4_std',\n",
        "       'mfcc5_mean', 'mfcc5_std', 'mfcc6_mean', 'mfcc6_std', 'mfcc7_mean',\n",
        "       'mfcc7_std', 'mfcc8_mean', 'mfcc8_std', 'mfcc9_mean', 'mfcc9_std',\n",
        "       'mfcc10_mean', 'mfcc10_std', 'mfcc11_mean', 'mfcc11_std', 'mfcc12_mean',\n",
        "       'mfcc12_std', 'mfcc13_mean', 'mfcc13_std', 'mfcc14_mean', 'mfcc14_std',\n",
        "       'mfcc15_mean', 'mfcc15_std', 'mfcc16_mean', 'mfcc16_std', 'mfcc17_mean',\n",
        "       'mfcc17_std', 'mfcc18_mean', 'mfcc18_std', 'mfcc19_mean', 'mfcc19_std',\n",
        "       'mfcc20_mean', 'mfcc20_std', 'mfcc21_mean', 'mfcc21_std', 'mfcc22_mean',\n",
        "       'mfcc22_std', 'mfcc23_mean', 'mfcc23_std', 'mfcc24_mean', 'mfcc24_std',\n",
        "       'mfcc25_mean', 'mfcc25_std', 'mfcc26_mean', 'mfcc26_std', 'mfcc27_mean',\n",
        "       'mfcc27_std', 'mfcc28_mean', 'mfcc28_std', 'mfcc29_mean', 'mfcc29_std',\n",
        "       'mfcc30_mean', 'mfcc30_std', 'mfcc31_mean', 'mfcc31_std', 'mfcc32_mean',\n",
        "       'mfcc32_std', 'mfcc33_mean', 'mfcc33_std', 'mfcc34_mean', 'mfcc34_std',\n",
        "       'mfcc35_mean', 'mfcc35_std', 'mfcc36_mean', 'mfcc36_std', 'mfcc37_mean',\n",
        "       'mfcc37_std', 'mfcc38_mean', 'mfcc38_std', 'mfcc39_mean', 'mfcc39_std',\n",
        "       'mfcc40_mean', 'mfcc40_std'\n",
        "]"
      ],
      "metadata": {
        "id": "0Mch-pCyFJ77"
      },
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "gender_features_df=gender_df[balanced_gender_features]"
      ],
      "metadata": {
        "id": "MsXD2pOFHi68"
      },
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "accent_features_df=accent_df[balanced_accent_features]"
      ],
      "metadata": {
        "id": "raLkSlAUHb3K"
      },
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "age_features_df=age_df[balanced_age_features]"
      ],
      "metadata": {
        "id": "OYQGddt8Hgnd"
      },
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Model Building"
      ],
      "metadata": {
        "id": "jjxH5tR2OR0e"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Set device to GPU if available\n",
        "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
        "print(f\"Using device: {device}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3V4VhdP4wz1y",
        "outputId": "447be574-3f6b-429f-bde3-786966e8524f"
      },
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Using device: cuda\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "###Gender model"
      ],
      "metadata": {
        "id": "zL1V_CxOJ-F6"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Gender Prediction Model\n",
        "class DenseGenderClassifier(nn.Module):\n",
        "    def __init__(self, input_size, num_classes=2):\n",
        "        super(DenseGenderClassifier, self).__init__()\n",
        "\n",
        "        self.model = nn.Sequential(\n",
        "            # Input layer with batch normalization\n",
        "            nn.BatchNorm1d(input_size),\n",
        "\n",
        "            # Dense block 1\n",
        "            nn.Linear(input_size, 1024),\n",
        "            nn.ReLU(),\n",
        "            nn.BatchNorm1d(1024),\n",
        "            nn.Dropout(0.2),\n",
        "\n",
        "            # Dense block 2\n",
        "            nn.Linear(1024, 1024),\n",
        "            nn.ReLU(),\n",
        "            nn.BatchNorm1d(1024),\n",
        "\n",
        "            # Dense block 3\n",
        "            nn.Linear(1024, 1024),\n",
        "            nn.ReLU(),\n",
        "            nn.BatchNorm1d(1024),\n",
        "            nn.Dropout(0.2),\n",
        "\n",
        "            # Dense block 4\n",
        "            nn.Linear(1024, 1024),\n",
        "            nn.ReLU(),\n",
        "            nn.BatchNorm1d(1024),\n",
        "\n",
        "            # Dense block 5\n",
        "            nn.Linear(1024, 1024),\n",
        "            nn.ReLU(),\n",
        "            nn.BatchNorm1d(1024),\n",
        "            nn.Dropout(0.2),\n",
        "\n",
        "            # Dense block 6\n",
        "            nn.Linear(1024, 1024),\n",
        "            nn.ReLU(),\n",
        "            nn.BatchNorm1d(1024),\n",
        "\n",
        "            # Final layers\n",
        "            nn.BatchNorm1d(1024),\n",
        "            nn.Dropout(0.2),\n",
        "            nn.Linear(1024, num_classes)\n",
        "        )\n",
        "\n",
        "    def forward(self, x):\n",
        "        return self.model(x)\n",
        "\n",
        "def train_gender_model(gender_features_df, epochs=50, batch_size=128):\n",
        "    \"\"\"Train a dense neural network model for gender prediction\"\"\"\n",
        "\n",
        "    # Prepare data\n",
        "    X = gender_features_df.drop(columns=['gender'])\n",
        "    le = LabelEncoder()\n",
        "\n",
        "    # Explicitly specify the class order to ensure consistent mapping\n",
        "    y = le.fit_transform(gender_features_df['gender'])\n",
        "\n",
        "    # Convert to numeric if needed\n",
        "    X = X.astype(float)\n",
        "\n",
        "    # Scale features\n",
        "    scaler = StandardScaler()\n",
        "    X_scaled = scaler.fit_transform(X)\n",
        "\n",
        "    # Split data into train, validation, and test sets\n",
        "    X_train, X_temp, y_train, y_temp = train_test_split(\n",
        "        X_scaled, y, test_size=0.3, random_state=42, stratify=y\n",
        "    )\n",
        "    X_val, X_test, y_val, y_test = train_test_split(\n",
        "        X_temp, y_temp, test_size=0.5, random_state=42, stratify=y_temp\n",
        "    )\n",
        "\n",
        "    # Convert to PyTorch tensors\n",
        "    X_train_tensor = torch.FloatTensor(X_train).to(device)\n",
        "    y_train_tensor = torch.LongTensor(y_train).to(device)\n",
        "    X_val_tensor = torch.FloatTensor(X_val).to(device)\n",
        "    y_val_tensor = torch.LongTensor(y_val).to(device)\n",
        "    X_test_tensor = torch.FloatTensor(X_test).to(device)\n",
        "    y_test_tensor = torch.LongTensor(y_test).to(device)\n",
        "\n",
        "    # Create DataLoaders\n",
        "    train_dataset = TensorDataset(X_train_tensor, y_train_tensor)\n",
        "    val_dataset = TensorDataset(X_val_tensor, y_val_tensor)\n",
        "    test_dataset = TensorDataset(X_test_tensor, y_test_tensor)\n",
        "\n",
        "    train_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True)\n",
        "    val_loader = DataLoader(val_dataset, batch_size=batch_size)\n",
        "    test_loader = DataLoader(test_dataset, batch_size=batch_size)\n",
        "\n",
        "    # Initialize model\n",
        "    input_size = X_train.shape[1]\n",
        "    model = DenseGenderClassifier(input_size, num_classes=2).to(device)\n",
        "\n",
        "    # Loss and optimizer\n",
        "    criterion = nn.CrossEntropyLoss()\n",
        "    optimizer = optim.Adam(model.parameters(), lr=1e-3)\n",
        "    scheduler = optim.lr_scheduler.ReduceLROnPlateau(optimizer, 'max', patience=3, factor=0.5, verbose=True)\n",
        "\n",
        "    best_val_accuracy = 0\n",
        "    early_stopping_counter = 0\n",
        "    patience = 5\n",
        "\n",
        "    # Training loop\n",
        "    for epoch in range(epochs):\n",
        "        model.train()\n",
        "        running_loss = 0.0\n",
        "\n",
        "        for inputs, labels in train_loader:\n",
        "            inputs, labels = inputs.to(device), labels.to(device)\n",
        "\n",
        "            # Forward pass\n",
        "            outputs = model(inputs)\n",
        "            loss = criterion(outputs, labels)\n",
        "\n",
        "            # Backward and optimize\n",
        "            optimizer.zero_grad()\n",
        "            loss.backward()\n",
        "            optimizer.step()\n",
        "\n",
        "            running_loss += loss.item()\n",
        "\n",
        "        # Validation evaluation\n",
        "        model.eval()\n",
        "        val_correct = 0\n",
        "        val_total = 0\n",
        "        val_loss = 0.0\n",
        "\n",
        "        with torch.no_grad():\n",
        "            for inputs, labels in val_loader:\n",
        "                inputs, labels = inputs.to(device), labels.to(device)\n",
        "                outputs = model(inputs)\n",
        "                val_loss += criterion(outputs, labels).item()\n",
        "                _, predicted = torch.max(outputs.data, 1)\n",
        "                val_total += labels.size(0)\n",
        "                val_correct += (predicted == labels).sum().item()\n",
        "\n",
        "        val_accuracy = 100 * val_correct / val_total\n",
        "        val_loss /= len(val_loader)\n",
        "        train_loss = running_loss / len(train_loader)\n",
        "\n",
        "        print(f'Epoch {epoch+1}, Train Loss: {train_loss:.4f}, Val Loss: {val_loss:.4f}, Val Accuracy: {val_accuracy:.2f}%')\n",
        "\n",
        "        # Learning rate scheduling\n",
        "        scheduler.step(val_accuracy)\n",
        "\n",
        "        # Early stopping check\n",
        "        if val_accuracy > best_val_accuracy:\n",
        "            best_val_accuracy = val_accuracy\n",
        "            early_stopping_counter = 0\n",
        "            torch.save(model.state_dict(), 'best_gender_model.pth')\n",
        "        else:\n",
        "            early_stopping_counter += 1\n",
        "            if early_stopping_counter >= patience:\n",
        "                print(f'Early stopping at epoch {epoch+1}')\n",
        "                break\n",
        "\n",
        "    # Load the best model\n",
        "    model.load_state_dict(torch.load('best_gender_model.pth'))\n",
        "\n",
        "    # Final test evaluation\n",
        "    model.eval()\n",
        "    test_correct = 0\n",
        "    test_total = 0\n",
        "\n",
        "    with torch.no_grad():\n",
        "        for inputs, labels in test_loader:\n",
        "            inputs, labels = inputs.to(device), labels.to(device)\n",
        "            outputs = model(inputs)\n",
        "            _, predicted = torch.max(outputs.data, 1)\n",
        "            test_total += labels.size(0)\n",
        "            test_correct += (predicted == labels).sum().item()\n",
        "\n",
        "    test_accuracy = 100 * test_correct / test_total\n",
        "    print(f'Final Test Accuracy: {test_accuracy:.2f}%')\n",
        "\n",
        "    print('Gender model training complete!')\n",
        "    return model, le, scaler"
      ],
      "metadata": {
        "id": "FTdumyp0wzzs"
      },
      "execution_count": 16,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "###Age Model"
      ],
      "metadata": {
        "id": "K9EUIDOEKDWt"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# 2. Age Prediction Model\n",
        "\n",
        "def prepare_age_data(df):\n",
        "    non_feat = ['age']\n",
        "    X = df.drop(columns=non_feat).values.astype(np.float32)\n",
        "\n",
        "    y_raw = df['age'].astype(str).str.strip().str.lower().values\n",
        "    y_raw = np.where(y_raw == 'fourties', 'forties', y_raw)  # normalize typo\n",
        "    classes, y = np.unique(y_raw, return_inverse=True)\n",
        "    n_classes = len(classes)\n",
        "    print('Age classes:', classes.tolist())\n",
        "\n",
        "    scaler = StandardScaler().fit(X)\n",
        "    X = scaler.transform(X)\n",
        "\n",
        "    X_tr, X_tmp, y_tr, y_tmp = train_test_split(\n",
        "        X, y, test_size=0.30, random_state=42, stratify=y)\n",
        "    X_va, X_te, y_va, y_te = train_test_split(\n",
        "        X_tmp, y_tmp, test_size=0.50, random_state=42, stratify=y_tmp)\n",
        "\n",
        "    return X_tr, X_va, X_te, y_tr, y_va, y_te, classes, scaler\n",
        "\n",
        "def build_mlp(dim_in, dim_out):\n",
        "    return nn.Sequential(\n",
        "        nn.Linear(dim_in, 2048), nn.BatchNorm1d(2048), nn.GELU(), nn.Dropout(0.2),\n",
        "        nn.Linear(2048, 1024), nn.BatchNorm1d(1024), nn.GELU(), nn.Dropout(0.1),\n",
        "        nn.Linear(1024, 512), nn.BatchNorm1d(512), nn.GELU(), nn.Dropout(0.1),\n",
        "        nn.Linear(512, 256), nn.BatchNorm1d(256), nn.GELU(), nn.Dropout(0.2),\n",
        "        nn.Linear(256, 128), nn.BatchNorm1d(128), nn.GELU(), nn.Dropout(0.1),\n",
        "        nn.Linear(128, 64), nn.BatchNorm1d(64), nn.GELU(), nn.Dropout(0.2),\n",
        "        nn.Linear(64, 32), nn.BatchNorm1d(32), nn.GELU(), nn.Dropout(0.1),\n",
        "        nn.Linear(32, dim_out)\n",
        "    ).to(device)\n",
        "\n",
        "def mask_features(x, p=0.10):\n",
        "    if p == 0:\n",
        "        return x\n",
        "    mask = torch.rand_like(x) < p\n",
        "    return x.masked_fill(mask, 0.0)\n",
        "\n",
        "def mixup(x, y, alpha=0.2):\n",
        "    lam = np.random.beta(alpha, alpha)\n",
        "    perm = torch.randperm(x.size(0), device=x.device)\n",
        "    return lam * x + (1 - lam) * x[perm], lam * y + (1 - lam) * y[perm]\n",
        "\n",
        "def train_one_age_model(seed, X_tr, y_tr, X_va, y_va, X_te, y_te, n_classes):\n",
        "    torch.manual_seed(seed)\n",
        "    np.random.seed(seed)\n",
        "    random.seed(seed)\n",
        "\n",
        "    def make_balanced_loader(X, y, batch=256, augment=False):\n",
        "        ds = TensorDataset(torch.tensor(X), torch.tensor(y))\n",
        "        if augment:\n",
        "            weights = 1. / np.bincount(y)[y]\n",
        "            sampler = WeightedRandomSampler(weights, len(weights))\n",
        "            return DataLoader(ds, batch_size=batch, sampler=sampler, pin_memory=True)\n",
        "        return DataLoader(ds, batch_size=batch, shuffle=False, pin_memory=True)\n",
        "\n",
        "    train_loader = make_balanced_loader(X_tr, y_tr, augment=True)\n",
        "    val_loader = make_balanced_loader(X_va, y_va)\n",
        "    test_loader = make_balanced_loader(X_te, y_te)\n",
        "\n",
        "    model = build_mlp(X_tr.shape[1], n_classes)\n",
        "    opt = torch.optim.AdamW(model.parameters(), lr=5e-4, weight_decay=2e-4)\n",
        "    sched = torch.optim.lr_scheduler.CosineAnnealingWarmRestarts(opt, T_0=10, T_mult=2)\n",
        "    loss_fn = nn.CrossEntropyLoss(label_smoothing=0.1)\n",
        "\n",
        "    swa_start = 40\n",
        "    swa_model = torch.optim.swa_utils.AveragedModel(model)\n",
        "    swa_sched = torch.optim.swa_utils.SWALR(opt, swa_lr=1e-4)\n",
        "\n",
        "    best_val = 0.0\n",
        "    best_state = None\n",
        "    wait = 0\n",
        "    EPOCHS, patience = 120, 12\n",
        "\n",
        "    for ep in range(1, EPOCHS + 1):\n",
        "        model.train()\n",
        "        for xb, yb in train_loader:\n",
        "            xb, yb = xb.to(device), yb.to(device)\n",
        "            xb = mask_features(xb, p=0.10)\n",
        "            xb, yb_soft = mixup(xb, F.one_hot(yb, n_classes).float())\n",
        "\n",
        "            opt.zero_grad()\n",
        "            loss = loss_fn(model(xb), yb_soft.argmax(1))\n",
        "            loss.backward()\n",
        "            opt.step()\n",
        "            sched.step()\n",
        "\n",
        "        if ep >= swa_start:\n",
        "            swa_model.update_parameters(model)\n",
        "            swa_sched.step()\n",
        "\n",
        "        model.eval()\n",
        "        preds = []\n",
        "        gold = []\n",
        "        with torch.no_grad():\n",
        "            for xb, yb in val_loader:\n",
        "                out = model(xb.to(device))\n",
        "                preds.append(out.argmax(1).cpu())\n",
        "                gold.append(yb)\n",
        "        val_acc = accuracy_score(torch.cat(gold), torch.cat(preds))\n",
        "\n",
        "        if val_acc > best_val:\n",
        "            best_val, best_state = val_acc, copy.deepcopy(model.state_dict())\n",
        "            wait = 0\n",
        "        else:\n",
        "            wait += 1\n",
        "            if wait >= patience:\n",
        "                break\n",
        "\n",
        "        if ep % 5 == 0:\n",
        "            print(f'Seed {seed} | Epoch {ep:3d} | val {val_acc * 100:5.2f}%')\n",
        "\n",
        "    model.load_state_dict(best_state)\n",
        "    torch.optim.swa_utils.update_bn(train_loader, swa_model, device=device)\n",
        "    return swa_model\n",
        "\n",
        "def eval_ensemble_age(models, loader):\n",
        "    logits_stack = []\n",
        "    for model in models:\n",
        "        model.eval()\n",
        "        logits = []\n",
        "        with torch.no_grad():\n",
        "            for xb, yb in loader:\n",
        "                logits.append(model(xb.to(device)))\n",
        "        logits_stack.append(torch.cat(logits))\n",
        "    return torch.stack(logits_stack).mean(0)\n",
        "\n",
        "def train_age_model(df):\n",
        "    X_tr, X_va, X_te, y_tr, y_va, y_te, classes, scaler = prepare_age_data(df)\n",
        "    n_classes = len(classes)\n",
        "\n",
        "    # Train 3 models with different seeds\n",
        "    seeds = [0, 1, 2]\n",
        "    models = [train_one_age_model(s, X_tr, y_tr, X_va, y_va, X_te, y_te, n_classes) for s in seeds]\n",
        "\n",
        "    # Ensemble evaluation\n",
        "    test_loader = DataLoader(\n",
        "        TensorDataset(torch.FloatTensor(X_te), torch.LongTensor(y_te)),\n",
        "        batch_size=256)\n",
        "\n",
        "    ensemble_logits = eval_ensemble_age(models, test_loader)\n",
        "    y_pred = ensemble_logits.argmax(1).cpu()\n",
        "    y_true = torch.cat([yb for xb, yb in test_loader])\n",
        "\n",
        "    test_acc = accuracy_score(y_true, y_pred)\n",
        "    print(f'\\nENSEMBLE TEST ACCURACY = {test_acc * 100:.2f}%')\n",
        "\n",
        "    return models[0], scaler, classes\n"
      ],
      "metadata": {
        "id": "bo32TXvKwzxi"
      },
      "execution_count": 17,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "###Accent Prediction Model"
      ],
      "metadata": {
        "id": "OkofX1e_KHMq"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Accentt Prediction Model\n",
        "def train_accent_model(accent_df):\n",
        "    le = LabelEncoder()\n",
        "    accent_df['accent_encoded'] = le.fit_transform(accent_df['accent'])\n",
        "    num_classes = len(np.unique(accent_df['accent_encoded']))\n",
        "\n",
        "    X = accent_df.drop(columns=['accent', 'accent_encoded']).values\n",
        "    y = accent_df['accent_encoded'].values\n",
        "\n",
        "    scaler = StandardScaler()\n",
        "    X = scaler.fit_transform(X)\n",
        "\n",
        "    X_train, X_test, y_train, y_test = train_test_split(X, y, stratify=y, test_size=0.2, random_state=42)\n",
        "\n",
        "    train_data = TensorDataset(torch.tensor(X_train, dtype=torch.float32), torch.tensor(y_train, dtype=torch.long))\n",
        "    test_data = TensorDataset(torch.tensor(X_test, dtype=torch.float32), torch.tensor(y_test, dtype=torch.long))\n",
        "\n",
        "    train_loader = DataLoader(train_data, batch_size=128, shuffle=True)\n",
        "    test_loader = DataLoader(test_data, batch_size=128)\n",
        "\n",
        "    class DeepMLPWithAttention(nn.Module):\n",
        "        def __init__(self, input_dim, hidden1, hidden2, hidden3, num_classes):\n",
        "            super(DeepMLPWithAttention, self).__init__()\n",
        "            self.fc1 = nn.Linear(input_dim, hidden1)\n",
        "            self.bn1 = nn.BatchNorm1d(hidden1)\n",
        "            self.drop1 = nn.Dropout(0.2)\n",
        "\n",
        "            self.fc2 = nn.Linear(hidden1, hidden2)\n",
        "            self.bn2 = nn.BatchNorm1d(hidden2)\n",
        "            self.drop2 = nn.Dropout(0.2)\n",
        "\n",
        "            self.fc3 = nn.Linear(hidden2, hidden3)\n",
        "            self.bn3 = nn.BatchNorm1d(hidden3)\n",
        "            self.drop3 = nn.Dropout(0.2)\n",
        "\n",
        "            self.attention = nn.Linear(hidden3, hidden3)\n",
        "            self.classifier = nn.Linear(hidden3, num_classes)\n",
        "\n",
        "        def forward(self, x):\n",
        "            x = F.relu(self.bn1(self.fc1(x)))\n",
        "            x = self.drop1(x)\n",
        "            x = F.relu(self.bn2(self.fc2(x)))\n",
        "            x = self.drop2(x)\n",
        "            x = F.relu(self.bn3(self.fc3(x)))\n",
        "            x = self.drop3(x)\n",
        "\n",
        "            attn_scores = torch.tanh(self.attention(x))\n",
        "            attn_weights = torch.softmax(attn_scores, dim=1)\n",
        "            x = x * attn_weights\n",
        "\n",
        "            return self.classifier(x)\n",
        "\n",
        "    class LabelSmoothingLoss(nn.Module):\n",
        "        def __init__(self, classes, smoothing=0.1):\n",
        "            super(LabelSmoothingLoss, self).__init__()\n",
        "            self.confidence = 1.0 - smoothing\n",
        "            self.smoothing = smoothing\n",
        "            self.cls = classes\n",
        "\n",
        "        def forward(self, x, target):\n",
        "            log_probs = F.log_softmax(x, dim=-1)\n",
        "            true_dist = torch.zeros_like(log_probs)\n",
        "            true_dist.fill_(self.smoothing / (self.cls - 1))\n",
        "            true_dist.scatter_(1, target.data.unsqueeze(1), self.confidence)\n",
        "            return torch.mean(torch.sum(-true_dist * log_probs, dim=-1))\n",
        "\n",
        "    def train_one_accent_model(seed):\n",
        "        torch.manual_seed(seed)\n",
        "        model = DeepMLPWithAttention(X.shape[1], 512, 256, 128, num_classes).to(device)\n",
        "        criterion = LabelSmoothingLoss(classes=num_classes, smoothing=0.1)\n",
        "        optimizer = torch.optim.Adam(model.parameters(), lr=0.0005)\n",
        "        scheduler = torch.optim.lr_scheduler.ReduceLROnPlateau(optimizer, mode='min', factor=0.5, patience=10)\n",
        "\n",
        "        best_model = None\n",
        "        best_acc = 0\n",
        "        patience = 15\n",
        "        no_improve = 0\n",
        "\n",
        "        for epoch in range(100):\n",
        "            model.train()\n",
        "            for inputs, labels in train_loader:\n",
        "                inputs, labels = inputs.to(device), labels.to(device)\n",
        "                optimizer.zero_grad()\n",
        "                outputs = model(inputs)\n",
        "                loss = criterion(outputs, labels)\n",
        "                loss.backward()\n",
        "                optimizer.step()\n",
        "\n",
        "            # Validation\n",
        "            model.eval()\n",
        "            correct = 0\n",
        "            total = 0\n",
        "            val_loss = 0.0\n",
        "            with torch.no_grad():\n",
        "                for inputs, labels in test_loader:\n",
        "                    inputs, labels = inputs.to(device), labels.to(device)\n",
        "                    outputs = model(inputs)\n",
        "                    loss = criterion(outputs, labels)\n",
        "                    val_loss += loss.item() * inputs.size(0)\n",
        "                    _, preds = torch.max(outputs, 1)\n",
        "                    total += labels.size(0)\n",
        "                    correct += (preds == labels).sum().item()\n",
        "\n",
        "            acc = 100 * correct / total\n",
        "            scheduler.step(val_loss)\n",
        "\n",
        "            if acc > best_acc:\n",
        "                best_acc = acc\n",
        "                best_model = model.state_dict()\n",
        "                no_improve = 0\n",
        "            else:\n",
        "                no_improve += 1\n",
        "                if no_improve >= patience:\n",
        "                    break\n",
        "\n",
        "        model.load_state_dict(best_model)\n",
        "        return model\n",
        "\n",
        "    seeds = [1, 42, 2025]\n",
        "    models = [train_one_accent_model(seed) for seed in seeds]\n",
        "\n",
        "    # Ensemble prediction\n",
        "    all_probs = []\n",
        "    for model in models:\n",
        "        model.eval()\n",
        "        probs = []\n",
        "        with torch.no_grad():\n",
        "            for inputs, _ in test_loader:\n",
        "                inputs = inputs.to(device)\n",
        "                outputs = F.softmax(model(inputs), dim=1)\n",
        "                probs.append(outputs.cpu())\n",
        "        all_probs.append(torch.cat(probs, dim=0))\n",
        "\n",
        "    ensemble_probs = torch.stack(all_probs).mean(dim=0)\n",
        "    ensemble_preds = torch.argmax(ensemble_probs, dim=1)\n",
        "    y_test_tensor = torch.tensor(y_test)\n",
        "    accuracy = (ensemble_preds == y_test_tensor).float().mean().item() * 100\n",
        "\n",
        "    print(f\"Ensemble Test Accuracy: {accuracy:.2f}%\")\n",
        "\n",
        "    return models[0], le, scaler"
      ],
      "metadata": {
        "id": "r4z6hYfPwzvG"
      },
      "execution_count": 18,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "###Main Function for training the model"
      ],
      "metadata": {
        "id": "_C3thOvgKLrB"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# ======================\n",
        "# Main Function\n",
        "# ======================\n",
        "\n",
        "def main():\n",
        "    \"\"\"Main function to train all models\"\"\"\n",
        "\n",
        "    # 1. Train Gender Model (Transformer)\n",
        "    print(\"\\nTraining Gender Model...\")\n",
        "    gender_model, gender_le, gender_scaler = train_gender_model(gender_features_df)\n",
        "\n",
        "    # Save gender model and preprocessing objects\n",
        "    torch.save({\n",
        "        'model_state_dict': gender_model.state_dict(),\n",
        "        'label_encoder': gender_le,\n",
        "        'scaler': gender_scaler\n",
        "    }, 'gender_model.pth')\n",
        "    print(\"Gender model saved to gender_model.pth\")\n",
        "\n",
        "    # 2. Train Age Model (SVM)\n",
        "    print(\"\\nTraining Age Model...\")\n",
        "    age_model, age_scaler, age_classes = train_age_model(age_features_df)\n",
        "\n",
        "    # Save age model and preprocessing objects\n",
        "    torch.save({\n",
        "        'model_state_dict': age_model.state_dict(),\n",
        "        'scaler': age_scaler,\n",
        "        'classes': age_classes\n",
        "    }, 'age_model.pth')\n",
        "    print(\"Age model saved to age_model.pth\")\n",
        "\n",
        "    # 3. Train Accent Model (LSTM)\n",
        "    print(\"\\nTraining Accent Model...\")\n",
        "    accent_model, accent_le, accent_scaler = train_accent_model(accent_features_df)\n",
        "\n",
        "    # Save accent model and preprocessing objects\n",
        "    torch.save({\n",
        "        'model_state_dict': accent_model.state_dict(),\n",
        "        'label_encoder': accent_le,\n",
        "        'scaler': accent_scaler\n",
        "    }, 'accent_model.pth')\n",
        "    print(\"Accent model saved to accent_model.pth\")\n",
        "\n",
        "\n",
        "    print(\"\\nAll models trained successfully!\")\n",
        "    return gender_model, gender_le, gender_scaler, age_model, age_scaler, age_classes, accent_model, accent_le, accent_scaler\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "    # Train models and get objects\n",
        "    (gender_model, gender_le, gender_scaler,\n",
        "     age_model, age_scaler, age_classes,\n",
        "     accent_model, accent_le, accent_scaler) = main()"
      ],
      "metadata": {
        "id": "BFlOa0d4wzln",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "f654cdbe-2006-4cef-e6c5-e9894b9148c7"
      },
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Training Gender Model...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/torch/optim/lr_scheduler.py:28: UserWarning: The verbose parameter is deprecated. Please use get_last_lr() to access the learning rate.\n",
            "  warnings.warn(\"The verbose parameter is deprecated. Please use get_last_lr() \"\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1, Train Loss: 0.2328, Val Loss: 0.1602, Val Accuracy: 94.16%\n",
            "Epoch 2, Train Loss: 0.1660, Val Loss: 0.1338, Val Accuracy: 94.87%\n",
            "Epoch 3, Train Loss: 0.1350, Val Loss: 0.1198, Val Accuracy: 95.55%\n",
            "Epoch 4, Train Loss: 0.1148, Val Loss: 0.1143, Val Accuracy: 95.55%\n",
            "Epoch 5, Train Loss: 0.1028, Val Loss: 0.1030, Val Accuracy: 96.20%\n",
            "Epoch 6, Train Loss: 0.0915, Val Loss: 0.0980, Val Accuracy: 96.22%\n",
            "Epoch 7, Train Loss: 0.0810, Val Loss: 0.1038, Val Accuracy: 95.98%\n",
            "Epoch 8, Train Loss: 0.0749, Val Loss: 0.0889, Val Accuracy: 96.48%\n",
            "Epoch 9, Train Loss: 0.0651, Val Loss: 0.0899, Val Accuracy: 96.62%\n",
            "Epoch 10, Train Loss: 0.0623, Val Loss: 0.0840, Val Accuracy: 96.60%\n",
            "Epoch 11, Train Loss: 0.0566, Val Loss: 0.0844, Val Accuracy: 96.95%\n",
            "Epoch 12, Train Loss: 0.0530, Val Loss: 0.0889, Val Accuracy: 97.07%\n",
            "Epoch 13, Train Loss: 0.0449, Val Loss: 0.0777, Val Accuracy: 97.32%\n",
            "Epoch 14, Train Loss: 0.0434, Val Loss: 0.0832, Val Accuracy: 97.05%\n",
            "Epoch 15, Train Loss: 0.0432, Val Loss: 0.0797, Val Accuracy: 97.31%\n",
            "Epoch 16, Train Loss: 0.0373, Val Loss: 0.0723, Val Accuracy: 97.46%\n",
            "Epoch 17, Train Loss: 0.0343, Val Loss: 0.0818, Val Accuracy: 97.15%\n",
            "Epoch 18, Train Loss: 0.0330, Val Loss: 0.0832, Val Accuracy: 97.42%\n",
            "Epoch 19, Train Loss: 0.0338, Val Loss: 0.0788, Val Accuracy: 97.24%\n",
            "Epoch 20, Train Loss: 0.0302, Val Loss: 0.0769, Val Accuracy: 97.37%\n",
            "Epoch 21, Train Loss: 0.0168, Val Loss: 0.0774, Val Accuracy: 97.79%\n",
            "Epoch 22, Train Loss: 0.0126, Val Loss: 0.0835, Val Accuracy: 97.59%\n",
            "Epoch 23, Train Loss: 0.0130, Val Loss: 0.0771, Val Accuracy: 97.67%\n",
            "Epoch 24, Train Loss: 0.0112, Val Loss: 0.0863, Val Accuracy: 97.62%\n",
            "Epoch 25, Train Loss: 0.0122, Val Loss: 0.0740, Val Accuracy: 97.88%\n",
            "Epoch 26, Train Loss: 0.0094, Val Loss: 0.0885, Val Accuracy: 97.77%\n",
            "Epoch 27, Train Loss: 0.0130, Val Loss: 0.0850, Val Accuracy: 97.65%\n",
            "Epoch 28, Train Loss: 0.0117, Val Loss: 0.0821, Val Accuracy: 97.72%\n",
            "Epoch 29, Train Loss: 0.0118, Val Loss: 0.0793, Val Accuracy: 97.86%\n",
            "Epoch 30, Train Loss: 0.0072, Val Loss: 0.0859, Val Accuracy: 98.01%\n",
            "Epoch 31, Train Loss: 0.0057, Val Loss: 0.0934, Val Accuracy: 97.96%\n",
            "Epoch 32, Train Loss: 0.0062, Val Loss: 0.0827, Val Accuracy: 97.99%\n",
            "Epoch 33, Train Loss: 0.0051, Val Loss: 0.0867, Val Accuracy: 98.01%\n",
            "Epoch 34, Train Loss: 0.0058, Val Loss: 0.0753, Val Accuracy: 98.01%\n",
            "Epoch 35, Train Loss: 0.0045, Val Loss: 0.0803, Val Accuracy: 98.00%\n",
            "Early stopping at epoch 35\n",
            "Final Test Accuracy: 97.83%\n",
            "Gender model training complete!\n",
            "Gender model saved to gender_model.pth\n",
            "\n",
            "Training Age Model...\n",
            "Age classes: ['fifties', 'forties', 'sixties', 'thirties', 'twenties']\n",
            "Seed 0 | Epoch   5 | val 79.88%\n",
            "Seed 0 | Epoch  10 | val 85.93%\n",
            "Seed 0 | Epoch  15 | val 86.49%\n",
            "Seed 0 | Epoch  20 | val 89.36%\n",
            "Seed 0 | Epoch  25 | val 87.33%\n",
            "Seed 0 | Epoch  30 | val 88.55%\n",
            "Seed 0 | Epoch  35 | val 90.26%\n",
            "Seed 0 | Epoch  40 | val 91.23%\n",
            "Seed 0 | Epoch  45 | val 88.58%\n",
            "Seed 0 | Epoch  50 | val 89.34%\n",
            "Seed 1 | Epoch   5 | val 80.61%\n",
            "Seed 1 | Epoch  10 | val 85.79%\n",
            "Seed 1 | Epoch  15 | val 86.89%\n",
            "Seed 1 | Epoch  20 | val 89.43%\n",
            "Seed 1 | Epoch  25 | val 86.82%\n",
            "Seed 1 | Epoch  30 | val 89.65%\n",
            "Seed 1 | Epoch  35 | val 90.91%\n",
            "Seed 1 | Epoch  40 | val 91.58%\n",
            "Seed 1 | Epoch  45 | val 89.22%\n",
            "Seed 1 | Epoch  50 | val 90.12%\n",
            "Seed 2 | Epoch   5 | val 80.24%\n",
            "Seed 2 | Epoch  10 | val 85.35%\n",
            "Seed 2 | Epoch  15 | val 85.90%\n",
            "Seed 2 | Epoch  20 | val 89.34%\n",
            "Seed 2 | Epoch  25 | val 87.49%\n",
            "Seed 2 | Epoch  30 | val 89.03%\n",
            "Seed 2 | Epoch  35 | val 90.38%\n",
            "Seed 2 | Epoch  40 | val 91.48%\n",
            "Seed 2 | Epoch  45 | val 89.39%\n",
            "Seed 2 | Epoch  50 | val 90.06%\n",
            "\n",
            "ENSEMBLE TEST ACCURACY = 93.07%\n",
            "Age model saved to age_model.pth\n",
            "\n",
            "Training Accent Model...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-18-c8cfca6f7a46>:4: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame.\n",
            "Try using .loc[row_indexer,col_indexer] = value instead\n",
            "\n",
            "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
            "  accent_df['accent_encoded'] = le.fit_transform(accent_df['accent'])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Ensemble Test Accuracy: 93.12%\n",
            "Accent model saved to accent_model.pth\n",
            "\n",
            "All models trained successfully!\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Model Prediction"
      ],
      "metadata": {
        "id": "OcsjY8YAKY5M"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#Feature extraction\n",
        "def extract_features(audio_path):\n",
        "    try:\n",
        "        # Load and preprocess audio\n",
        "        waveform, sr = torchaudio.load(audio_path)\n",
        "        if sr != 16000:\n",
        "            waveform = F_audio.resample(waveform, sr, 16000)\n",
        "\n",
        "        # Convert to mono if needed\n",
        "        if waveform.shape[0] > 1:\n",
        "            waveform = waveform.mean(dim=0, keepdim=True)\n",
        "\n",
        "        # Standardize length to 3 seconds (48000 samples at 16kHz)\n",
        "        target_length = 3 * 16000\n",
        "        if waveform.shape[-1] < target_length:\n",
        "            waveform = torch.nn.functional.pad(waveform, (0, target_length - waveform.shape[-1]))\n",
        "        else:\n",
        "            waveform = waveform[..., :target_length]\n",
        "\n",
        "        waveform = waveform.to(device)\n",
        "        features = {}\n",
        "\n",
        "        # Initialize transforms (move to device once)\n",
        "        mfcc_transform = MFCC(\n",
        "            sample_rate=16000,\n",
        "            n_mfcc=40,\n",
        "            melkwargs={\"n_fft\": 1024, \"hop_length\": 256, \"n_mels\": 64}\n",
        "        ).to(device)\n",
        "\n",
        "        mel_spec = MelSpectrogram(\n",
        "            sample_rate=16000,\n",
        "            n_fft=1024,\n",
        "            hop_length=256,\n",
        "            n_mels=64\n",
        "        ).to(device)\n",
        "\n",
        "        spectrogram = Spectrogram(\n",
        "            n_fft=1024,\n",
        "            win_length=512,\n",
        "            hop_length=256,\n",
        "            power=2\n",
        "        ).to(device)\n",
        "\n",
        "        # MFCC features (40 coefficients)\n",
        "        mfccs = mfcc_transform(waveform).squeeze()\n",
        "        for i in range(mfccs.shape[0]):\n",
        "            features[f'mfcc{i+1}_mean'] = mfccs[i].mean().item()\n",
        "            features[f'mfcc{i+1}_std'] = mfccs[i].std().item()\n",
        "\n",
        "        # Mel features\n",
        "        mel = mel_spec(waveform)\n",
        "        features.update({\n",
        "            'mel_energy_mean': mel.mean().item(),\n",
        "            'mel_energy_std': mel.std().item()\n",
        "        })\n",
        "\n",
        "        # Spectral features\n",
        "        spec = spectrogram(waveform)\n",
        "        freqs = torch.linspace(0, 8000, spec.shape[-1], device=device)\n",
        "        spec_sum = spec.sum(dim=-1) + 1e-8\n",
        "        spectral_centroid = (spec * freqs).sum(dim=-1) / spec_sum\n",
        "\n",
        "        spec_diff = torch.diff(spec.float(), dim=-1)\n",
        "        spectral_flux = torch.mean(spec_diff**2).item()\n",
        "\n",
        "        features.update({\n",
        "            'spectral_centroid_mean': spectral_centroid.mean().item(),\n",
        "            'spectral_centroid_std': spectral_centroid.std().item(),\n",
        "            'spectral_flux': spectral_flux\n",
        "        })\n",
        "\n",
        "        # Energy features\n",
        "        frame_length = 512\n",
        "        hop_length = 256\n",
        "        frames = waveform.unfold(-1, frame_length, hop_length)\n",
        "        rms = torch.sqrt(torch.mean(frames**2, dim=-1))\n",
        "\n",
        "        # Zero crossing rate\n",
        "        zcr = (waveform[:, :-1] * waveform[:, 1:] < 0).float().mean().item()\n",
        "\n",
        "        features.update({\n",
        "            'rms_mean': rms.mean().item(),\n",
        "            'rms_std': rms.std().item(),\n",
        "            'zero_crossing_rate': zcr,\n",
        "            'energy_variability': rms.std().item() / (rms.mean().item() + 1e-8)\n",
        "        })\n",
        "\n",
        "        # Pitch features\n",
        "        pitch = F_audio.detect_pitch_frequency(waveform, 16000)\n",
        "        pitch = pitch[pitch > 0]\n",
        "\n",
        "        if len(pitch) > 0:\n",
        "            pitch_diff = torch.diff(pitch.float())\n",
        "            features.update({\n",
        "                'pitch_mean': pitch.mean().item(),\n",
        "                'pitch_std': pitch.std().item(),\n",
        "                'pitch_range': (pitch.max() - pitch.min()).item(),\n",
        "                'jitter_local': (torch.mean(torch.abs(pitch_diff))) / (pitch.mean().item() + 1e-8),\n",
        "                'voiced_fraction': len(pitch) / (waveform.shape[-1] // 256)\n",
        "            })\n",
        "        else:\n",
        "            features.update({\n",
        "                'pitch_mean': 0.0,\n",
        "                'pitch_std': 0.0,\n",
        "                'pitch_range': 0.0,\n",
        "                'jitter_local': 0.0,\n",
        "                'voiced_fraction': 0.0\n",
        "            })\n",
        "        return features\n",
        "\n",
        "    except Exception as e:\n",
        "        print(f\"Error processing audio: {str(e)}\")\n",
        "        return None"
      ],
      "metadata": {
        "id": "wyAEq_SnCk2V"
      },
      "execution_count": 20,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Remove 'age' from balanced_age list which is already initialised at first\n",
        "balanced_age_features = [f for f in balanced_age_features if f != 'age']\n",
        "\n",
        "# Remove 'accent' from balanced_accent list which is already initialised at first\n",
        "balanced_accent_features = [f for f in balanced_accent_features if f != 'accent']\n",
        "\n",
        "# Remove 'gender' from balanced_gender list which is already initialised at first\n",
        "balanced_gender_features = [f for f in balanced_gender_features if f != 'gender']"
      ],
      "metadata": {
        "id": "Q0bhmqP5GJSh"
      },
      "execution_count": 21,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Prediction model call"
      ],
      "metadata": {
        "id": "x_kXl1TIKwHz"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def predict_audio_attributes(audio_path):\n",
        "    # Extract features from the audio file\n",
        "    features = extract_features(audio_path)\n",
        "    if features is None:\n",
        "        print(\"Failed to extract features from audio file\")\n",
        "        return None\n",
        "\n",
        "    # Create a DataFrame from the features\n",
        "    features_df = pd.DataFrame([features])\n",
        "\n",
        "    # Prepare feature sets for each model\n",
        "    age_features = features_df[[f for f in balanced_age_features if f != 'age']]\n",
        "    accent_features = features_df[[f for f in balanced_accent_features if f != 'accent']]\n",
        "    gender_features = features_df[[f for f in balanced_gender_features if f != 'gender']]\n",
        "\n",
        "    # Make predictions\n",
        "\n",
        "    # 1. Gender prediction\n",
        "    gender_features_scaled = gender_scaler.transform(gender_features)\n",
        "    gender_input = torch.FloatTensor(gender_features_scaled).to(device)\n",
        "    gender_model.eval()\n",
        "    with torch.no_grad():\n",
        "        gender_output = gender_model(gender_input)\n",
        "    gender_pred = gender_output.argmax(1).item()\n",
        "    gender_label = gender_le.inverse_transform([gender_pred])[0]\n",
        "\n",
        "    # 2. Age prediction\n",
        "    age_features_scaled = age_scaler.transform(age_features)\n",
        "    age_input = torch.FloatTensor(age_features_scaled).to(device)\n",
        "    age_model.eval()\n",
        "    with torch.no_grad():\n",
        "        age_output = age_model(age_input)\n",
        "    age_pred = age_output.argmax(1).item()\n",
        "    age_label = age_classes[age_pred]\n",
        "\n",
        "    # 3. Accent prediction\n",
        "    accent_features_scaled = accent_scaler.transform(accent_features)\n",
        "    accent_input = torch.FloatTensor(accent_features_scaled).to(device)\n",
        "    accent_model.eval()\n",
        "    with torch.no_grad():\n",
        "        accent_output = accent_model(accent_input)\n",
        "    accent_pred = accent_output.argmax(1).item()\n",
        "    accent_label = accent_le.inverse_transform([accent_pred])[0]\n",
        "\n",
        "    # 4. Speech-to-text using Whisper\n",
        "    try:\n",
        "        # Load the Whisper model (you can choose different sizes: tiny, base, small, medium, large)\n",
        "        whisper_model = whisper.load_model(\"base\")  # Adjust based on your needs\n",
        "\n",
        "        # Transcribe the audio file\n",
        "        result = whisper_model.transcribe(audio_path)\n",
        "        transcribed_text = result[\"text\"]\n",
        "    except Exception as e:\n",
        "        print(f\"Error in Whisper transcription: {str(e)}\")\n",
        "        transcribed_text = \"Transcription failed\"\n",
        "\n",
        "    return {\n",
        "        'gender': gender_label,\n",
        "        'age': age_label,\n",
        "        'accent': accent_label,\n",
        "        'transcribed_text': transcribed_text\n",
        "    }"
      ],
      "metadata": {
        "id": "lKPU9zYeOXAR"
      },
      "execution_count": 22,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Upload your speech audio here\n"
      ],
      "metadata": {
        "id": "6Dquxm90K2Ug"
      },
      "execution_count": 30,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "audio_path = \"/content/samprat3.mp3\" #add your path for the audio"
      ],
      "metadata": {
        "id": "Y6NLX_pHCgCV"
      },
      "execution_count": 89,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "features = extract_features(audio_path)"
      ],
      "metadata": {
        "id": "sdqEo9s7wzes"
      },
      "execution_count": 90,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "pre_df = pd.DataFrame([features]) #Converting extracted features into dataframe"
      ],
      "metadata": {
        "id": "_p0gG4nFFoi8"
      },
      "execution_count": 91,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "age_pred_df=pre_df[balanced_age_features]\n",
        "accent_pred_df=pre_df[balanced_accent_features]\n",
        "gender_pred_df=pre_df[balanced_gender_features]"
      ],
      "metadata": {
        "id": "4U69Go_JC2r4"
      },
      "execution_count": 92,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#OUTPUTS"
      ],
      "metadata": {
        "id": "YdUwVZLoLMec"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#Outputs\n",
        "predictions = predict_audio_attributes(audio_path)\n",
        "\n",
        "if predictions:\n",
        "    print(\"\\nPrediction Results:\")\n",
        "    print(f\"Gender: {predictions['gender']}\")\n",
        "    print(f\"Age Group: {predictions['age']}\")\n",
        "    print(f\"Accent: {predictions['accent']}\")\n",
        "    print(f\"Transcribed Text: {predictions['transcribed_text']}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hNEBDEZeQoP8",
        "outputId": "a96cbf1a-18c4-46e7-87df-dbe5fa18174b"
      },
      "execution_count": 93,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/sklearn/utils/validation.py:2732: UserWarning: X has feature names, but StandardScaler was fitted without feature names\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.11/dist-packages/sklearn/utils/validation.py:2732: UserWarning: X has feature names, but StandardScaler was fitted without feature names\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Prediction Results:\n",
            "Gender: male\n",
            "Age Group: thirties\n",
            "Accent: us\n",
            "Transcribed Text:  Hi my name is Sam Pratt, I am from California.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "FWLLrXofdqqq"
      },
      "execution_count": 88,
      "outputs": []
    }
  ]
}